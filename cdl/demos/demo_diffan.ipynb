{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 1 CUDA device(s).\n"
     ]
    }
   ],
   "source": [
    "from cdl.data import sachs\n",
    "from cdl.metrics import evaluate_graph\n",
    "from cdl.utils import is_dag\n",
    "from cdl.models.diffan import DiffAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch:  21%|██        | 631/3000 [00:13<00:49, 47.91it/s, Epoch Loss=0.585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stoping at epoch 631\n",
      "Best model at epoch 330 with loss 0.48792383074760437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes ordered :  10%|█         | 1/10 [00:00<00:06,  1.40it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 368.00 MiB (GPU 0; 1.96 GiB total capacity; 1.09 GiB already allocated; 352.44 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m n_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(G)\n\u001B[1;32m      3\u001B[0m diffan \u001B[38;5;241m=\u001B[39m DiffAN(n_nodes, residue\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, masking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 4\u001B[0m G_est, order \u001B[38;5;241m=\u001B[39m \u001B[43mdiffan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# mt = MetricsDAG(adj_matrix, true_causal_matrix).metrics\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# mt[\"sid\"] = SID(true_causal_matrix, adj_matrix).item()\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     print(mt)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# assert is_dag(G_est)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# acc = evaluate_graph(G, G_est != 0)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# acc\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/python/CausalDiscoveryLibrary/cdl/models/diffan/diffan.py:57\u001B[0m, in \u001B[0;36mDiffAN.fit\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     55\u001B[0m X \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mFloatTensor(X)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_score(X)\n\u001B[0;32m---> 57\u001B[0m order \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtopological_ordering\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m out_dag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpruning(order, X\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_dag, order\n",
      "File \u001B[0;32m~/projects/python/CausalDiscoveryLibrary/cdl/models/diffan/diffan.py:146\u001B[0m, in \u001B[0;36mDiffAN.topological_ordering\u001B[0;34m(self, X, step, eval_batch_size)\u001B[0m\n\u001B[1;32m    143\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(X, eval_batch_size, drop_last \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    145\u001B[0m model_fn_functorch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_function_with_residue(steps, active_nodes, order)\n\u001B[0;32m--> 146\u001B[0m leaf_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_jacobian_and_get_leaf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_fn_functorch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msorting:\n\u001B[1;32m    148\u001B[0m     order \u001B[38;5;241m=\u001B[39m leaf_\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m~/projects/python/CausalDiscoveryLibrary/cdl/models/diffan/diffan.py:190\u001B[0m, in \u001B[0;36mDiffAN.compute_jacobian_and_get_leaf\u001B[0;34m(self, data_loader, active_nodes, model_fn_functorch)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_batch \u001B[38;5;129;01min\u001B[39;00m data_loader:\n\u001B[1;32m    189\u001B[0m     x_batch_dropped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_masked(x_batch, active_nodes) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasking \u001B[38;5;28;01melse\u001B[39;00m x_batch\n\u001B[0;32m--> 190\u001B[0m     jacobian_ \u001B[38;5;241m=\u001B[39m \u001B[43mvmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjacrev\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_fn_functorch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch_dropped\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m    191\u001B[0m     jacobian\u001B[38;5;241m.\u001B[39mappend(jacobian_[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,active_nodes]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m    192\u001B[0m jacobian \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(jacobian, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:362\u001B[0m, in \u001B[0;36mvmap.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m _check_out_dims_is_int_or_int_pytree(out_dims, func)\n\u001B[1;32m    361\u001B[0m batch_size, flat_in_dims, flat_args, args_spec \u001B[38;5;241m=\u001B[39m _process_batched_inputs(in_dims, args, func)\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_flat_vmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_in_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandomness\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:35\u001B[0m, in \u001B[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfn\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mdisable_saved_tensors_hooks(message):\n\u001B[0;32m---> 35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:489\u001B[0m, in \u001B[0;36m_flat_vmap\u001B[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     batched_inputs \u001B[38;5;241m=\u001B[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001B[0;32m--> 489\u001B[0m     batched_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatched_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    490\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001B[1;32m    491\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:474\u001B[0m, in \u001B[0;36mjacrev.<locals>.wrapper_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    471\u001B[0m flat_basis \u001B[38;5;241m=\u001B[39m _construct_standard_basis_for(flat_output, flat_output_numels)\n\u001B[1;32m    472\u001B[0m basis \u001B[38;5;241m=\u001B[39m tree_unflatten(flat_basis, output_spec)\n\u001B[0;32m--> 474\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mvmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvjp_fn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbasis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    476\u001B[0m primals \u001B[38;5;241m=\u001B[39m _slice_argnums(args, argnums)\n\u001B[1;32m    477\u001B[0m flat_primals, primals_spec \u001B[38;5;241m=\u001B[39m tree_flatten(primals)\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:362\u001B[0m, in \u001B[0;36mvmap.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m _check_out_dims_is_int_or_int_pytree(out_dims, func)\n\u001B[1;32m    361\u001B[0m batch_size, flat_in_dims, flat_args, args_spec \u001B[38;5;241m=\u001B[39m _process_batched_inputs(in_dims, args, func)\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_flat_vmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_in_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandomness\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:35\u001B[0m, in \u001B[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfn\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mdisable_saved_tensors_hooks(message):\n\u001B[0;32m---> 35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/vmap.py:489\u001B[0m, in \u001B[0;36m_flat_vmap\u001B[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     batched_inputs \u001B[38;5;241m=\u001B[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001B[0;32m--> 489\u001B[0m     batched_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatched_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    490\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001B[1;32m    491\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:323\u001B[0m, in \u001B[0;36m_vjp_with_argnums.<locals>.wrapper\u001B[0;34m(cotangents, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m primals_out_spec \u001B[38;5;241m!=\u001B[39m cotangents_spec:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected pytree structure of cotangents to be the same \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mas pytree structure of outputs to the function. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcotangents: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtreespec_pprint(cotangents_spec)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprimal output: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtreespec_pprint(primals_out_spec)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 323\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43m_autograd_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mflat_primals_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_diff_primals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_cotangents\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tree_unflatten(result, primals_spec)\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:113\u001B[0m, in \u001B[0;36m_autograd_grad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(diff_outputs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(torch\u001B[38;5;241m.\u001B[39mzeros_like(inp) \u001B[38;5;28;01mfor\u001B[39;00m inp \u001B[38;5;129;01min\u001B[39;00m inputs)\n\u001B[0;32m--> 113\u001B[0m grad_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdiff_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m grad_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(torch\u001B[38;5;241m.\u001B[39mzeros_like(inp) \u001B[38;5;28;01mif\u001B[39;00m gi \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m gi\n\u001B[1;32m    118\u001B[0m                     \u001B[38;5;28;01mfor\u001B[39;00m gi, inp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(grad_inputs, inputs))\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m grad_inputs\n",
      "File \u001B[0;32m~/anaconda3/envs/CausalDiscovery/lib/python3.9/site-packages/torch/autograd/__init__.py:300\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001B[0m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(grad_outputs_)\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 368.00 MiB (GPU 0; 1.96 GiB total capacity; 1.09 GiB already allocated; 352.44 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "G, X = sachs(as_df=False)\n",
    "n_nodes = len(G)\n",
    "diffan = DiffAN(n_nodes, residue= True, masking=False)\n",
    "G_est, order = diffan.fit(X)\n",
    "# mt = MetricsDAG(adj_matrix, true_causal_matrix).metrics\n",
    "# mt[\"sid\"] = SID(true_causal_matrix, adj_matrix).item()\n",
    "#     print(mt)\n",
    "# assert is_dag(G_est)\n",
    "# acc = evaluate_graph(G, G_est != 0)\n",
    "# acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}